[TOC]

# MIT S6.S081——xv6: a simple, Unix-like teaching operating system

### Chapter 1 Operating system interfaces

#### 1.2 I/O and File descriptors

1. wait(int *status)只要一有子进程结束就会返回，status可以是空指针即wait((int * 0))，这表明我们不关心子进程结束的具体状态，只关心其是否结束，并返回结束的子进程的pid

2. ==fork&exec==: fork creates a copy of the shell process. 

   - 文件描述符表的继承：当子进程被创建时，它会继承父进程的文件描述符表的副本。这意味着，子进程会得到一个和父进程相同的文件描述符表，这个表中包含了父进程在创建子进程时所打开的所有文件描述符的副本。

   - 文件描述符的共享：子进程的文件描述符是父进程的副本，并且它们指向相同的文件表项。这意味着，子进程和父进程可以同时访问相同的文件，而不会相互影响。

   - 文件描述符的独立性：子进程和父进程在运行时可以独立地关闭文件描述符，而不会影响对方的文件描述符。例如，如果子进程关闭了一个文件描述符，那么父进程的对应文件描述符仍然保持打开状态，反之亦然。

   - 一旦fork&exec合并成一条call，就无法在中间重定向，因此必须是separate的两条

   - ==例==：

     ```c++
     char *argv[2];
     argv[0] = "cat";
     argv[1] = 0;
     if(fork() == 0) {
     close(0);
     open("input.txt", O_RDONLY);
     exec("cat", argv);
     }
     /*这段代码是一个在UNIX或类UNIX系统中使用fork-exec模型创建子进程并执行外部命令的示例。让我解释一下：
     首先，定义了一个指针数组 argv，用于存储传递给 exec 函数的参数列表。在这个例子中，argv[0] 被设置为 "cat"，表示要执行的命令是 cat，argv[1] 被设置为 0，表示参数列表的结束。
     接着，通过 fork() 函数创建了一个子进程。如果 fork() 返回值为0，则表示当前代码正在执行的是子进程；如果返回值不为0，则表示当前代码正在执行的是父进程。
     在子进程中，首先关闭文件描述符0，即标准输入。然后通过 open 函数打开文件 "input.txt"，并且使用 O_RDONLY 标志表示以只读方式打开。由于文件描述符0此时是最小的可用文件描述符，因此 open 函数会使用文件描述符0来表示 "input.txt" 文件。
     最后，调用 exec 函数来执行 "cat" 命令。exec 函数将加载一个新的程序替换当前进程的内容。在这里，它会加载 "cat" 程序，并传递 argv 参数列表给它。由于之前关闭了文件描述符0并打开了 "input.txt" 文件，因此 "cat" 程序会从标准输入读取 "input.txt" 文件的内容。
     在父进程中，子进程的文件描述符修改不会影响到父进程的文件描述符。因此，父进程的文件描述符保持不变。
     总的来说，这段代码创建了一个子进程，关闭了标准输入，并将 "input.txt" 文件作为标准输入传递给了 "cat" 命令，同时父进程的文件描述符保持不变。*/
     ```

3. dup指令和fork出来的子进程copy的fd一样，都保存相同的offset

   ```
   fd = dup(1);
   write(1, "hello ", 6);
   write(fd, "world\n", 6);
   ```

   这能确保write的是hello world。2024.4.18

### Chapter 2 Operation system organization

操作系统三要素：multiplexing, isolation, interaction

#### 2.2 User mode, supervisor mode and syscalls

1. isolation由CPU来提供硬件支持。一般CPU先处在machine mode in which it can have full privilege, 来配置电脑，如何转向supervisor mode（能执行privileged instruction）

#### 2.5 Process overview

1. To ensure isolation, the process abstraction provides the illusion to a program that it has its own private machine. 
   **Xv6 uses page tables (which are implemented by hardware) to give each process its own address space.** 

2. PAGE TABLE: 

   The RISC-V page table translates (or “maps”) a virtual address (the address that an RISC-V instruction manipulates) to a physical address (an address that the CPU chip sends to main memory).

3. Address space(each process owns one):

   an address space includes the process’s user memory starting at virtual address 0. Instructions come first, followed by global variables, then the stack, and finally a “heap” area (for malloc) that the process can expand as needed.

![image-20240420172705989](C:\Users\95684\AppData\Roaming\Typora\typora-user-images\image-20240420172705989.png)

#### 2.6 Starting xv6 and the first process

整个启动流程可以简单概括如下：

1. **计算机上电和初始化：** 当RISC-V计算机上电时，硬件进行自我初始化，并运行存储在只读内存中的引导加载程序（boot loader）。
2. **加载xv6内核：** 引导加载程序将xv6内核加载到内存中。内核被加载到物理地址0x80000000处，因为前面的地址范围（0x0到0x80000000）包含I/O设备。
3. **CPU执行内核：** 在机器模式下，CPU从内核的入口点开始执行，即_entry（kernel/entry.S:6）处的位置。
4. **设置栈和切换到C代码：** _entry处的指令设置了一个栈，以便xv6可以运行C代码。然后调用C代码中的start函数。
5. **进入监管模式：** start函数执行一些配置，然后切换到监管模式。这涉及将特权模式设置为监管模式，并进行一些必要的设置，例如设置返回地址为main函数的地址，禁用虚拟地址转换等。
6. **定时器中断配置：** 在进入监管模式之前，start函数还配置了时钟芯片以生成定时器中断。
7. **切换到main函数：** start函数最后通过调用mret指令“返回”到监管模式，从而导致程序计数器跳转到main函数。
8. **初始化设备和子系统：** main函数初始化了系统中的各种设备和子系统。
9. **创建第一个进程：** main函数最后通过调用userinit函数创建了第一个进程。这个进程执行了一个小的以RISC-V汇编编写的程序initcode.S，该程序通过exec系统调用重新进入内核。
10. **启动shell：** 最终，用户空间中的/init进程在控制台上启动了一个shell，系统启动完毕。 2024.4.20

#### 课程笔记

1. 确保isolation的核心思想：对硬件资源进行抽象化. strong isolation is required between apps and os. Typical method: virtual memory and user/kernel(supervisor) mode.

2. process是对cpu的抽象，一个process代表一个cpu的核，比如xv6是四核，代表同时最多有4个process。操作系统做的：如果有8给application，操作系统会使用一些核，通过**时间复用**来运行，比如运行一个应用100ms，unload from cpu，再跑另一个for 100ms，确保没有一个应用程序跑超过100ms，由此实现时间服用。

3. exec：对内存（memory）进行抽象。操作系统提供内存隔离，exec系统调用展示了不能直接访问硬件内存。files也是一个例子：files是对磁盘块(disk block)的抽象，操作系统决定如何map文件到磁盘，确保文件之间独立。

4. USER/KERNEL MODE

   In kernel mode, cpu can exec privileged instructions, in user mode only unprivileged ones can be executed. 

5. VIRTURAL MEMORY:
   PAGE TABLE: virtual add -> physical
   each process owns its own page table

6. HOW WE ENTER THE KERNEL:
   ecall <n>,n is the syscall number
   eg: call fork() in user space, it doesn't call fork() directly. Instead we call ecall and enters the kernel and calls the function syscall.c which looks for the number provided by ecall and call fork().

7. KERNEL = TCB(trusted computing base):
   -- must have no bugs
   -- must treat user processs as malicious

### Lab 1

#### gdb环境配置

1. echo "add-auto-load-safe-path /home/steven/xv6-labs-2021/.gdbinit" >> ~/.gdbinit
   其中:"/home/steven/xv6-labs-2021/.gdbinit"根据情况改
2. 一台终端上跑make qemu-gdb(在XV6文件夹下)
   另一台跑gdb-multiarch即可开始调试。

#### 预习

1. echo.c
   * argc是命令行参数数量，argv是具体传入的字符串数组
   * 参数数量大于等于1，参数之间以空格分隔，第一个参数默认为程序名称；如：echo fuck you是3个参数，argv[0]是echo, argv[1]是fuck...

#### sleep.c

没什么好说的

#### pingpong.c

use wait() or sleep(1) in parent process to ensure isolation

#### primes.c

<img src="C:\Users\95684\AppData\Roaming\Typora\typora-user-images\image-20240422195621431.png" alt="image-20240422195621431" style="zoom: 200%;" />



### Lab 2

#### trace.c

user.h的系统调用接口不用真正执行。实际系统调用的步骤：

当用户调用int trace(int mask)，实际上通过usys.pl中的entry，执行了：

```ca65
# usys.S
.global trace
trace:
 li a7, SYS_trace
 ecall
 ret
```

重点是把SYS_trace放进a7，**然后调用ecall指令**，从用户态切入内核态。
内核态中的sys_trace()从用户态fetch参数，设置proc结构体中的mask的值。之后每次调用其他syscall时，默认初始要调用入口函数syscall.c，syscall.c比较当前进程的mask值和trace设置的mask值是否一样，一样则输出该syscall和它用的进程号。



### Chapter 3 Page Table

#### 3.1 paging hardware

* RISV-V用低39bits作为虚拟地址的索引，高25位不使用

* page table 是 PTE(page table entry)的数组，共2^27^个PTE

* Each PTE contains a 44-bit physical page number (PPN) and some flags. The paging hardware translates a virtual address by using the top 27 bits of the 39 bits to index into the page table to find a PTE, and making a 56-bit physical address whose top 44 bits come from the PPN in the PTE and whose bottom 12 bits are copied from the original virtual address. PPN: PAGE TABLE NUMBER

  ![image-20240520181849997](C:\Users\95684\AppData\Roaming\Typora\typora-user-images\image-20240520181849997.png)

![image-20240520181909540](C:\Users\95684\AppData\Roaming\Typora\typora-user-images\image-20240520181909540.png)



#### 3.2 kernel address space

* 每个进程一个页表描述该进程的user space；除此之外还有一个单独页表描述kernel space
* `qemu`把device接口存在特定控制寄存器中，kernel通过访问这些寄存器的物理地址和他们交互
  * 这些device和RAM（硬件资源）采用直接mapping，虚拟地址等于他们的硬件地址
  * 一些不是直接mapping的kernel虚拟地址：
    * trampoline page
    * kernel stack page

#### 3.3 creating an address space

* 机器启动过程：
  1. main调用`kvminit`创建内核页表
     1. 分配一页物理内存存放root page table
     2. 调用`kvmmap`将内核要用的hardware device映射到物理地址
  2. `kvmmap`调用`mappages`将指定范围的虚拟地址映射到一段物理地址
     1. 将范围内`vm`分成多页，每次map一页的起始地址
     2. 对于map的每一页的起始地址，调用walk找到该地址的最后一级PTE的地址
     3. 配置PTE
  3. walk逐级（每次降低9位）查找三级页表，用前一级的9位虚拟地址查找下一级的PTE;若PTE无效则未被分配，分配一个新的页表页并把其物理地址放在PTE中。**这样做就节省了空间，不必提前分配那么多页表，实现on-demanding page allocation**

#### 3.4 physical memory allocation

xv6 kernel运行时为页表、用户内存、内核堆栈和缓冲区分配和释放内存

* 一次malloc&free以4096B的page为单位
* 通过一个链表记录空闲页
* 分配：删链表节点 释放页面：加链表节点



2024.5.21

#### 3.5 code: physical memory allocator

* 数据结构

  * 分配器的数据结构是一个 *物理地址页*   的 *free list*
  * *free list*中每个 *free physical page* 中的元素是一个结构体*run*
  * 每个*free page*的*run*存储在each *free page*自己的memory中

* 程序流程

  * 示意图：

    `main`
      `|`
      `v`
    `kinit`
      `|`
      `v`
    `freerange`
      `|`
      `v`
    `kfree (for each page)`
      `|`
      `v`
    `kalloc (when memory is requested)`

  * function main calls kinit

    * kinit `init` the free list to hold every page between the end of the kernel and PHYSTOP

    * kinit calls `freerange` to add memory to the free list via per-page calls to `kfree`.（allocator最开始没有memory，必须`kfree`调用后才有可管理的内存）

    * `kfree` 函数开始时将被释放的内存中的每个字节设置为1。这将导致在释放后使用内存的代码（使用“悬挂引用”）读取垃圾，而不是旧的有效内容；hopefully这将使这样的代码更快地出错。然后 `kfree` 将页面添加到自由列表的开头：它将 `pa` 转换为指向 `struct run` 的指针，记录自由列表的旧开始在 `r->next` 中，并将自由列表设置为 `r`。`kalloc` 删除并返回`freelist` 中的第一个元素。

    * PTE和page双射，一个PTE（页表条目）map到一个物理页

      * **A PTE can only refer to a physical address that is aligned on a 4096-byte boundary (is a multiple of 4096)**
      * 页表条目（Page Table Entry，PTE）只能引用对齐在4096字节边界的物理地址。"对齐在4096字节边界"的意思是这个地址是4096的倍数。因为PTE引用页，每页大小4096B




#### 3.6 process address space

* 每个进程一个页表，切换进程会改变页表。一个进程原则上允许寻址256GB内存空间

  ![image-20240521190744464](C:\Users\95684\AppData\Roaming\Typora\typora-user-images\image-20240521190744464.png)

* 当一个进程要求 xv6 提供更多的用户内存时，xv6 首先使用 `kalloc` 来分配物理页，然后将指向新物理页的 PTE 添加到进程的页表中。

* 概念界定

  * 页：内存分配的基本单位，4096B(4KB)
  * PTE：64位 8B 包含44位`vm`和10位标志信息，指向一页page
  * 页表：PTE的数组

  ![image-20240521191203509](C:\Users\95684\AppData\Roaming\Typora\typora-user-images\image-20240521191203509.png)

* 内核在用户地址空间的顶部映射了一个包含trampoline代码的页。因此，这个物理内存页会出现在所有的地址空间中

  * 解释：当内核在用户地址空间的顶部映射一个包含trampoline代码的页时，它实际上是在每个进程的页表中都添加了一个指向这个物理页的条目。因此，这个物理页就会出现在所有进程的地址空间中。

    这并不是因为物理页被映射到了地址空间的顶部，而是因为内核在每个进程的页表中都添加了相应的映射。无论这个物理页被映射到地址空间的哪个位置，只要所有进程的页表中都有相应的映射，这个物理页就会出现在所有进程的地址空间中。

    这种方法的一个好处是，可以让所有进程共享一块物理内存，从而节省内存。另一个好处是，可以让所有进程都能访问到一些特定的代码或数据，例如trampoline代码。

#### 3.7 code: `sbrk`

* 控制进程内存增长/减少
* 流程：
  * 调用`growporc`，根据n正负调用 `uvmalloc` 或 `uvmdealloc`
  * `uvmalloc`通过`kalloc`分配物理内存，再使用`mappages`将PTE添加到用户页表
  * `uvmdealloc` 调用 `uvmunmap`（`kernel/vm.c:174`），它使用 `walk` 来查找 PTE 并使用 `kfree` 来释放它们所引用的物理内存。

#### 3.8 code: `exec`



#### 课程4笔记：Page Table

1. memory isolation

   basic idea: each process has its own address space, totally independent with each other.

2. MMU(memory management unit) just translate the mapping, it doesn't store the mapping.
   Through certain registers like satp, it tells the cpu where to find the relation of vm and pa and do the mapping. 切换应用程序（进程）时所谓的切换页表，实际是切换satp REG(由内核kernel存储每个进程的satp的值)，pointing to the according mapping of the application.

3. **Translation**

   * page size:4KB

   * per-address :x:
     per-page  :heavy_check_mark:

   * `vm`的PTE分为 27-bit index and 12-bit offset (还有高25bit unused)， thus now `vm` space is 512GB
     adding offset to the base of the page we get the correct physical address

     为什么offset 12-bit？**因为2^12^ = 4096**, one page has 4096B. Why index 27-bit? we will see later.

   * `pa`  is 56-bit(44+12) -> `pa` can be bigger than a single `vm` 
     Why 56bits? 设计师预测的而已。12bit offset对应page size，剩下的就用来做index了

4. **Real Hardware-implemented Structure of Page Table **

   * ==三级结构==——27bit被分为3个9bit
     top 9bit -> 4096B大的顶层页表目录（Page Directory）

   * 每级目录共512个PTE，每个PTE 8B大（总共64bit（64bit = 8 * 8bit）, like the REG）

   * 实际发生的是：

     * satp指向top Page Directory的**vertual adddress**

     * 用顶层的目录以及top 9 bits的index找到PTE。PTE中含下一级的physical page number，即next level 的 Page directory，（**具体而言，是用这个顶层目录的PTE中的44位，再补上12个0得到下一级目录的物理地址**）然后用mid 9bits, 在这个PTE给出的page中（第二级page）找到一个PTE，由此导向第三级page，再用low 9bits找到最终的physical address

       即：**第三级page directory中，由low 9bit 指向的PTE中的44bit PPN再加上原始虚拟地址的12位offset，才是我们真正要从虚拟地址 map 到的真正的物理地址**

   * 三级结构优点：如果地址空间的大部分空间没被使用，我们就不需要为他们分配PTE

     * 如：在一个地址空间中只有1个page（4096B）
       则27位地址全为0——高中低9位都为0，只需要三级页表中每级各1个PTE即可，现在需要的大小为3 page directories，即3*512个entry。

       而：原本的一级页表需要2^27^个entry

5. 真实世界中的优化

   三级结构要求三次访存，开销很大！！！

   实际会使用**Translation look-aside Buffer(TLB)**——一个cache，存储最近访问的PTE
   存[VA, PA]，优先访问TLB而非三级页表

   TLB在CPU内，空间很小

6. xv6中的kernel page layout

   ![image-20240521213319668](C:\Users\95684\AppData\Roaming\Typora\typora-user-images\image-20240521213319668.png)

   左：VM

   右：PA（DRAM和IO devices）

   * 0x8000...0以下的所有物理地址不是指向DRAM，而是直接指向IO设备
   * 大部分都是恒等映射
     * 有些page在memory中很高的位置，原因是底下有个guard page防止溢出。放高点so that不浪费物理地址（对应在unused 物理地址）
     * **栈这些被map了twice，一次在unused的地方，一次在实际的物理地址中**（below PHYSTOP）
   * 每个用户进程都有一个对应的kernel stack




#### Calling convention 2024.6.1

1. RISC-V调用约定尽可能在寄存器中传递参数，使用八个整数寄存器a0-a7和八个浮点寄存器fa0-fa7。
2. 如果函数的参数可以被看作是C结构体的字段，那么参数寄存器就是这个结构体中前八个指针字长参数的副本。
3. 如果参数是浮点类型，它会在浮点寄存器中传递，除非它是union或结构体中数组字段的一部分，或者它是变参函数的参数，这些情况下它会在整数寄存器中传递。
4. 小于指针字长的参数在参数寄存器的最低有效位中传递。如果在栈上传递，它们会出现在指针字的较低地址中，因为RISC-V是小端存储系统。
5. 当在堆栈上传递两倍于指针字大小的基本参数时，它们是自然对齐的。当它们在整数寄存器中传递时，它们驻留在对齐的偶数号-奇数号寄存器对中，偶数寄存器保存最低有效位。
6. 大于指针字大小两倍的参数通过引用传递。
7. 结构体中未在参数寄存器中传递的部分在栈上传递。栈指针sp指向未在寄存器中传递的第一个参数。
8. 函数在整数寄存器a0和a1以及浮点寄存器fa0和fa1中返回值。只有当浮点值是原始值或作为仅有一两个浮点值组成的结构体的成员时，才会从浮点寄存器中返回。长度恰好为两个指针字长的其他返回值将在a0和a1中返回。较大的返回值完全在内存中传递；调用方分配此内存区域，并将指针作为隐式的第一个参数传递给被调用方。

#### 课程5笔记：RISC-V Calling Convention

1. REG是around CPU的（汇编work on REG instead of memory）

2. caller-saved reg can be overwritten by function
   callee-saved reg cannot, they are preserved across function call

3. **Stack**: what keep functions organized

   * each time we call a function, there is a **stack** **frame**
     it moves around by moving the **sp ** (stack pointer), which points to the **bottom of the stack**(in terms of the address, bottom = lowest address -> the most recent stack frame)

   * stack grows from high to lower address, so the calculation of sp is usually accomplished by  subtraction
   * stack frame size varies, **but return address and pointer to previous frame(fp) are always on the 1st and 2nd top space**. 
   * fp -> **top** of the **current frame**

![image-20240601203541958](C:\Users\95684\AppData\Roaming\Typora\typora-user-images\image-20240601203541958.png)





### Lab3

1. preparation之源码阅读

   1. kalloc.c

      * `run`结构体，只包含指向下一个run的指针，用于连接空闲页表
      * `void kfree(void *pa)`：读入一个物理地址的指针，把该物理地址内容置1便于调试，然后将其加入空闲链表
      * `void * kalloc(void)`:用结构体run从空闲链表的表头读取一个页，表头后移，用memset把该页内容置成5便于调试，返回指向该页物理地址的指针
      * `void freerange`(void *pa_start, void *pa_end)：从start到end逐页调用kfree
      * `void kinit()`:初始化，对end到PHYSTOP调用freerange

   2. vm.c

      * `kvmmake`: 创建并初始化内核的页表，映射内核和设备的内存。
      * `kvminit`: 初始化内核的页表。
      * `kvminithart`: 切换硬件页表寄存器到内核的页表，并启用分页。
      * `walk`: 返回对应于虚拟地址的页表中的页表项（PTE）的地址。如果需要，创建任何必需的页表页。
      * `walkaddr`: 查找虚拟地址，返回物理地址，如果未映射则返回0。只能用于查找用户页。
      * `kvmmap`: 在引导时向内核页表添加映射。不刷新TLB或启用分页。
      * `mappages`: 为从虚拟地址开始引用从物理地址开始的PTE创建PTE。va和size可能不是页对齐的。如果walk()无法分配所需的页表页，则返回0。
      * `uvmunmap`: 从va开始删除npages的映射。va必须是页对齐的。映射必须存在。可选地释放物理内存。（unmap是通过*pte = 0来实现的，主要是对pagetable中的pte进行操作，用walk找到每个va对应的pte）
      * `uvmcreate`: 创建一个空的用户页表。如果内存不足，返回0。
      * `uvminit`: 将用户initcode加载到页表的地址0，用于第一个进程。sz必须小于一页。
      * `uvmalloc`: 分配PTE和物理内存以使进程从oldsz增长到newsz，这不需要是页对齐的。返回新的大小，如果出错则返回0。
      * `uvmdealloc`: 释放用户页以将进程大小从oldsz减小到newsz。oldsz和newsz不需要是页对齐的，newsz也不需要小于oldsz。oldsz可以大于实际的进程大小。返回新的进程大小。
      * `freewalk`: 递归地释放页表页。所有叶子映射必须已经被移除。
      * `uvmfree`: 先释放用户内存页，然后释放页表页。
      * `uvmcopy`: 给定一个父进程的页表，将其内存复制到子进程的页表。复制页表和物理内存。成功返回0，失败返回-1，失败时释放任何已分配的页。
      * `uvmclear`: 标记一个PTE对用户访问无效。被exec用于用户栈保护页。
      * `copyout`: 从内核复制到用户。从src复制len字节到给定页表的虚拟地址dstva。成功返回0，错误返回-1。
      * `copyin`: 从用户复制到内核。从给定页表的虚拟地址srcva复制len字节到dst。成功返回0，错误返回-1。
      * `copyinstr`: 从用户复制一个以null结尾的字符串到内核。从给定页表的虚拟地址srcva复制字节到dst，直到'\0'或max。成功返回0，错误返回-1。

   3. 部分（我觉得）困难函数的详解

      1. `int copyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len)：`

         首先，`va0 = PGROUNDDOWN(dstva); pa0 = walkaddr(pagetable, va0);`获取了目标的虚拟和物理地址；

         然后，计算**每一次在一页内最多可复制的**字节数`n`:
         `n = PGSIZE - (dstva - va0);`
         比如 dstva = 5000, PGSIZE = 4096，则va0 = 4096（向下取整了），dstva - va0 = 904
         4096 - 904 = 3192，即这一次在一页内最多可复制`n = 3192`个字节
         `len`是总共要复制的字节数`n`比`len`大就只复制`len`个字节
         每次复制为一次循环，该次循环结束后更新`len src dstva`值得注意的是`dstva`会直接加PGSIZE，跳到下一个页的起始地址

         最后，`memmove(dst, (void *)(pa0 + (srcva - va0)), n);`
         `pa0 + (srcva - va0))`实际上源地址在物理内存中的实际位置